{% extends "springeval/base.html" %}

{% block content %}

<p>
  Welcome to the Spring and RobustSpring datasets and evaluation benchmark for stereo, optical flow, and scene flow estimation, including robustness evaluation under 20 realistic image corruptions!
</p>


<div style="margin: auto;width: 100%">
    <div class="startbutton">
        <a href="https://doi.org/10.18419/darus-3376" target="_blank" rel="noopener noreferrer">
            <h1>&#11015;</h1>
            <p>Download<br>Spring<br>dataset</p>
        </a>
    </div>
    <div class="startbutton">
        <a href="https://doi.org/10.18419/DARUS-5047" target="_blank" rel="noopener noreferrer">
            <h1>&#11015;</h1>
            <p>Download<br>RobustSpring<br>dataset</p>
        </a>
    </div>
    <div class="startbutton">
        <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Mehl_Spring_A_High-Resolution_High-Detail_Dataset_and_Benchmark_for_Scene_Flow_CVPR_2023_paper.pdf"
            target="_blank" rel="noopener noreferrer">
            <h1>&#x1F4C4;</h1>
            <p>Spring<br>Paper<br>&nbsp;</p>
        </a>
    </div>
    <div class="startbutton">
        <a href="https://arxiv.org/abs/2505.09368" target="_blank" rel="noopener noreferrer">
            <h1>&#x1F4C4;</h1>
            <p>RobustSpring<br>Paper<br>&nbsp;</p>
        </a>
    </div>
    <div class="startbutton">
        <a href="https://openaccess.thecvf.com/content/CVPR2023/supplemental/Mehl_Spring_A_High-Resolution_CVPR_2023_supplemental.pdf"
            target="_blank" rel="noopener noreferrer">
            <h1>&#x1F4C4;</h1>
            <p>Spring<br>Suppl.<br>Material</p>
        </a>
    </div>
    <div class="startbutton">
        <a href="https://arxiv.org/abs/2303.01943" target="_blank" rel="noopener noreferrer">
            <h1>&#x1F4C4;</h1>
            <p>Spring<br>Paper<br>(ArXiv)</p>
        </a>
    </div>
    <div class="startbutton">
        <a href="https://cloud.visus.uni-stuttgart.de/index.php/s/5MtTY23RWcWfgPE" target="_blank"
            rel="noopener noreferrer">
            <h1>&#11015;</h1>
            <p>Download<br>Spring<br>sample</p>
        </a>
    </div>
    <div class="startbutton">
        <a href="https://www.youtube.com/watch?v=omcntkTrFTg" target="_blank" rel="noopener noreferrer">
            <h1>&#9654;</h1>
            <p>View</br>Video<br>&nbsp;</p>
        </a>
    </div>
    <div class="startbutton">
        <a href="https://github.com/cv-stuttgart/sceneflow_from_blender" target="_blank" rel="noopener noreferrer">
            <h1>&lt;/&gt;</h1>
            <p>Code<br>(Blender)<br>&nbsp;</p>
        </a>
    </div>
    <div class="startbutton">
        <a href="https://github.com/cv-stuttgart/springwebsite" target="_blank" rel="noopener noreferrer">
            <h1>&lt;/&gt;</h1>
            <p>Code<br>(Website)<br>&nbsp;</p>
        </a>
    </div>
</div>

{% load static %}

<div class="teaserimg" style="margin-top:1em;">
    <figure>
        <img width="100%" src="{% static 'springeval/teaserimage.png' %}" alt="Teaser image">
        <figcaption>
            The Spring dataset consists of high-resolution left and right <b>stereo images</b> (1920×1080px). It also
            contains full scene flow data with 4× super-resolution (3840×2160px). For stereo/depth estimation,
            left-to-right and right-to-left <b>disparity</b> is given for every frame (see second row). For scene flow
            estimation, the dataset provides <b>disparity change</b> for left and right as well as forward and backward
            direction (see third row). For optical flow estimation, the Spring dataset contains left and right, forward
            and backward <b>optical flow</b> (see last row).
        </figcaption>
    </figure>
</div>

<div class="teaserimg" style="margin-top:2em;">
    <figure>
        <img width="100%" src="{% static 'springeval/robustspring.png' %}" alt="RobustSpring overview">
        <figcaption>
            RobustSpring is a novel image corruption benchmark for optical flow, scene flow and stereo. It evaluates 20
            image corruptions including blurs, color changes, noises, quality degradations, and weather, applied to
            stereo video data from Spring. For comprehensive robustness evaluations on all three tasks, RobustSpring's
            image corruptions are integrated in time, stereo and depth where applicable.
        </figcaption>
    </figure>
</div>

<h3>News</h3>
<ul>
    <li>
        <strong>May 15, 2025:</strong> We're excited to launch <em>RobustSpring</em>, a new robustness extension of the
        Spring benchmark for stereo, optical flow, and scene flow. Download the dataset and start evaluating your models
        under 20 realistic image corruptions: <a href="https://doi.org/10.18419/DARUS-5047" target="_blank"
            rel="noopener noreferrer">Get RobustSpring (DOI: 10.18419/DARUS-5047)</a>.
    </li>
    <li>July 17, 2023: We corrected two erroneous train sequences: The forward right eye ground truth of sequences 0002
        and 0020 now correctly contains forward flow instead of backward flow. Please make sure to <a
            href="https://doi.org/10.18419/darus-3376" target="_blank" rel="noopener noreferrer">download the latest
            version</a> of <code>train_flow_FW_right.zip</code>, <code>train_disp2_FW_right.zip</code> and
        <code>train_maps.zip</code>. All other files and the test split data is unaffected. We thank Sander Gielisse for
        notifying us!
    </li>
    <li>June 20, 2023: We present our paper at <a href="https://cvpr2023.thecvf.com/" target="_blank"
            rel="noopener noreferrer">CVPR 2023</a>. Check out our <a href="https://www.youtube.com/watch?v=omcntkTrFTg"
            target="_blank" rel="noopener noreferrer">video</a> and <a
            href="https://cvpr2023.thecvf.com/media/PosterPDFs/CVPR%202023/22734.png" target="_blank"
            rel="noopener noreferrer">poster</a>.</li>
    <li>June 05, 2023: We publish our code to <a href="https://github.com/cv-stuttgart/sceneflow_from_blender"
            target="_blank" rel="noopener noreferrer">generate 3D motion / scene flow from Blender</a> and the full code
        of <a href="https://github.com/cv-stuttgart/springwebsite" target="_blank" rel="noopener noreferrer">this
            benchmark webpage</a>.</li>
    <li>March 20, 2023: Starting today we accept submissions of registered users. You can submit once per hour and up to
        three times per 30 days.</li>
    <li>March 14, 2023: Our full dataset is now available for <a href="https://doi.org/10.18419/darus-3376"
            target="_blank" rel="noopener noreferrer">download</a>!</li>
    <li>March 03, 2023: Hello world &ndash; our website is launched! We make a small sample available for download.</li>
</ul>

<h3>Paper</h3>
<p>If you make use of our dataset or benchmark results, please cite our <a href="https://arxiv.org/abs/2303.01943"
        target="_blank" rel="noopener noreferrer">Spring</a> and <a href="https://arxiv.org/abs/2505.09368"
        target="_blank" rel="noopener noreferrer">RobustSpring</a> papers:</p>
<pre><code>@InProceedings{Mehl2023_Spring,
    author    = {Lukas Mehl and Jenny Schmalfuss and Azin Jahedi and Yaroslava Nalivayko and Andr\'es Bruhn},
    title     = {Spring: A High-Resolution High-Detail Dataset and Benchmark for Scene Flow, Optical Flow and Stereo},
    booktitle = {Proc. IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2023}
}
</code></pre>
<pre><code>@misc{Schmalfuss2025_RobustSpring,
    author={Jenny Schmalfuss and Victor Oei and Lukas Mehl and Madlen Bartsch and Shashank Agnihotri and Margret Keuper and Andr\'es Bruhn},
    title={RobustSpring: Benchmarking Robustness to Image Corruptions for Optical Flow, Scene Flow and Stereo}, 
    eprint={2505.09368},
    archivePrefix={arXiv}
    year={2025},
}
</code></pre>

<h3>Further benchmarks</h3>
<p>There are many benchmarks that have been pushing forward research in the domains of motion estimation and stereo.
    Most notable examples are the <a href="https://vision.middlebury.edu/flow/" target="_blank"
        rel="noopener noreferrer">Middlebury optical flow</a> and <a href="https://vision.middlebury.edu/stereo/"
        target="_blank" rel="noopener noreferrer">stereo benchmark</a>, the <a
        href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow.php?benchmark=flow" target="_blank"
        rel="noopener noreferrer">KITTI 2012 optical flow</a> and <a
        href="https://www.cvlibs.net/datasets/kitti/eval_stereo_flow.php?benchmark=stereo" target="_blank"
        rel="noopener noreferrer">stereo benchmark</a>, the <a href="http://sintel.is.tue.mpg.de/" target="_blank"
        rel="noopener noreferrer">Sintel optical flow benchmark</a>, <a
        href="https://www.cvlibs.net/datasets/kitti/eval_scene_flow.php" target="_blank" rel="noopener noreferrer">KITTI
        2015</a> as the first benchmark for <a href="https://www.cvlibs.net/datasets/kitti/eval_scene_flow.php"
        target="_blank" rel="noopener noreferrer">scene flow</a>, <a
        href="https://www.cvlibs.net/datasets/kitti/eval_scene_flow.php?benchmark=flow" target="_blank"
        rel="noopener noreferrer">optical flow</a> and <a
        href="https://www.cvlibs.net/datasets/kitti/eval_scene_flow.php?benchmark=stereo" target="_blank"
        rel="noopener noreferrer">stereo</a>, the <a href="https://www.eth3d.net/" target="_blank"
        rel="noopener noreferrer">ETH3D stereo benchmark</a>, the <a href="http://hci-benchmark.iwr.uni-heidelberg.de/"
        target="_blank" rel="noopener noreferrer">HD1K benchmark</a>, and the <a
        href="https://playing-for-benchmarks.org/" target="_blank" rel="noopener noreferrer">VIPER optical flow
        benchmark</a>.
    As a great addition to existing benchmarks, the <a href="http://www.robustvision.net/" target="_blank"
        rel="noopener noreferrer">Robust Vision Challenge</a> ranks algorithms according to their cross-benchmark
    generalization.

</p>

{% endblock %}